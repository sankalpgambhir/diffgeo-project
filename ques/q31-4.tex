\begin{frame}{}
\frametitle{Problem Set 3.1 - 4}
\textbf{Check that the diamond and square metrics on $\bm{\mathbb{R}^n}$ are
indeed metrics. Show that the euclidean metric on $\bm{\mathbb{R}^n}$ is indeed
a metric. (The triangle inequality in this context is equivalent to Minkowskiâ€™s
inequality.)}\hfill\break
\hfill\break
For any ${x},{y} \in \mathbb{R}^n $ where $x = (x_1, x_2, \ldots,x_n)$: 
\begin{enumerate}
    \item Diamond metric: $d_1({x},{y}) = \sum_{i\in \mathcal{I}} |x_i - y_i| $
    \item Euclidean metric: $d_2({x},{y}) = \sqrt{\sum_{i\in \mathcal{I}} |x_i -
    y_i|^2} $
    \item Square metric: $d_{\infty}({x},{y}) = max_{i\in \mathcal{I}}\{|x_i -
    y_i|\}$
\end{enumerate}
\hfill\break
Now we just have to show that each of these metrics satisfy the four conditions
that characterise metric spaces. We will look at each metric separately.
\end{frame}

\begin{frame}{}
\textit{The Diamond metric}\hfill\break
\begin{itemize}
        \item $d_1(x,x) = \sum_{i=1}^{n} |x_i - x_i| = 0$.
        \hfill\break
    % edit line here >>> - Sankalp
    \pause
    \item  We know that that
    for $p \in \mathbb{R}, |p|\geq 0$ and $|p| = 0 \iff p = 0$ (positive
    definite). \hfill\break
    \hfill\break
    Let us assume that there exists distinct $x,y$ such that $d_1(x,y) = \sum_{i=1}^{n} |x_i - y_i| = 0$.\hfill\break
    \hfill\break
    However for the assumption to hold, $|x_i - y_i| = 0$ for all
    $i \in \mathcal{I}$. Hence $x_i = y_i$. This
    shows that for $x\neq y$, $d_1(x,y)>0$.
\end{itemize}
\end{frame}

\begin{frame}{}
\begin{itemize}
    \item We can rewrite $d_1(x,y) = \sum_{i=1}^{n} |x_i - y_i| = \sum_{i=1}^{n}
    |- (- x_i + y_i)| = \sum_{i=1}^{n} |y_i -
    x_i |.$ Therefore, $d_1(x,y) = d_1(y,x).$ \hfill\break
    \pause
    \item We use the inequality $|(x_i - y_i) + (y_i - z_i)| \leq |x_i -
    y_i| + |y_i - z_i| \Rightarrow |x_i - z_i| \leq |x_i - y_i| + |y_i - z_i|$.\hfill\break
    \hfill\break
    Taking the summation, $\sum_{i=1}^{n}|x_i - z_i| \leq \sum_{i=1}^{n}|x_i -
    y_i| + \sum_{i=1}^{n}|y_i - z_i|$. \\
    Hence, we have shown, $d_1(x,z) \leq
    d_1(x,y)+d_1(y,z).$
\end{itemize}
\end{frame}

\begin{frame}
\textit{The Euclidean metric}\hfill\break
\begin{itemize}
    \item $d_2(x,x) = \sqrt{\sum_{i=1}^{n} |x_i - x_i|^2} = 0$.\hfill\break
    \item We know
    that that for $p \in \mathbb{R}, \sqrt{p}\geq0$ and $\sqrt{p} = 0 \iff p =
    0$ (positive definite). \hfill\break
    \hfill\break
    Suppose $d_2(x,y) = \sqrt{\sum_{i=1}^{n} |x_i - y_i|^2} = 0$. \hfill\break
    \hfill\break
    Therefore for the assumption to hold,
    $\sum_{i=1}^{n} |x_i - y_i|^2 = 0$. Further, $ |x_i - y_i|^2 = 0$ for all $i
    \in \mathcal{I}$. Hence $x_i = y_i$. This shows that for $x\neq y$,
    $d_2(x,y)>0$.
\end{itemize}
\end{frame}


\begin{frame}
\textit{The Euclidean metric}\hfill\break
\begin{itemize}
    \item We can rewrite $d_2(x,y) = \sqrt{\sum_{i=1}^{n} |x_i - y_i|^2} =
    \sqrt{\sum_{i=1}^{n} |- (- x_i + y_i)|^2} = \sqrt{\sum_{i=1}^{n} |y_i - x_i|^2}.$ Therefore, $d_2(x,y) =
    d_2(y,x).$\hfill\break
    \pause
    \item Minkowski's inequality* says that
    $(\sum_{k=1}^{n}|\alpha_k+\beta_k|^p)^\frac{1}{p} \leq
    (\sum_{k=1}^{n}|\alpha_k|^p)^\frac{1}{p} +
    (\sum_{k=1}^{n}|\beta_k|^p)^\frac{1}{p}$.\hfill\break
    \hfill\break
    If we substitute $\alpha_k =
    x_k-y_k$, $\beta_k = y_k - z_k$ and $p=2$, we get the desired triangle inequality.\hfill\break
    $ \sqrt{\sum_{i=1}^{n} |x_i - z_i|^2} \leq  \sqrt{\sum_{i=1}^{n} |x_i -
    y_i|^2} +  \sqrt{\sum_{i=1}^{n} |y_i - z_i|^2}$. \\ Hence, we have shown,
    $d_2(x,z) \leq d_2(x,y)+d_2(y,z).$
\end{itemize}
\end{frame}

\begin{frame}
\textit{The Square metric}\hfill\break
\begin{itemize}
     \item $d_{\infty}(x,x) = max_{i\in \mathcal{I}}\{|x_i - x_i|\} = max\{0,
    0,..,0\} = 0$\hfill\break
    \item We know that that for $p \in \mathbb{R}, |p|\geq 0$ and $|p| = 0
    \iff p = 0$ (positive definite). \hfill\break
    \hfill\break
    Let us assume $d_{\infty}(x,y) = max_{i\in \mathcal{I}}\{|x_i - y_i|\} = 0$
    at $i=i*$. \hfill\break\hfill\break
    Therefore for the assumption to hold, $|x_i
    - y_i| \leq 0$ for all $i \in \mathcal{I}, i\neq i*$ $\Rightarrow |x_i -
    y_i| = 0$. Hence $x_i = y_i$. This shows that
    for $x\neq y$, $d_{\infty}(x,y)>0$.
\end{itemize}
\end{frame}

\begin{frame}
\textit{The Square metric}\hfill\break
\begin{itemize}
    \item We can rewrite $d_{\infty}(x,y) = max_{i\in \mathcal{I}}\{|x_i -
    y_i|\} = max_{i\in \mathcal{I}}\{|- (- x_i + y_i)|\} = max_{i\in \mathcal{I}}\{|y_i - x_i|\}.$
    Therefore, $d_{\infty}(x,y) = d_{\infty}(y,x).$ \hfill\break
    \pause
    \item For $x,y,z \in \mathbb{R}$ we have proven the triangle inequality $|x_1 - z_1| \leq |x_1 - y_1| + |y_1 - z_1|$.  \hfill\break
    \hfill\break
     Now, for $x,y,z \in \mathbb{R}^n$, let $k \in \mathcal{I}$ correspond to $max_{i\in \mathcal{I}}\{|x_i - z_i|\} = |x_k - z_k|.$ \hfill\break
     So, $|x_k - z_k| \leq |x_k - y_k| + |y_k - z_k|$
     \hfill\break
     \hfill\break
    $ |x_k - y_k| \leq max_{i\in \mathcal{I}}\{|x_i - y_i|\} = d_{\infty}(x,y)$
     \\
     $ |y_k - z_k| \leq max_{i\in \mathcal{I}}\{|y_i - z_i|\} = d_{\infty}(y,z)$
     \hfill\break
     \hfill\break
     Hence, $ max_{i\in \mathcal{I}}\{|x_i -
    z_i|\} \leq max_{i\in \mathcal{I}}\{|x_i - y_i|\} + max_{i\in \mathcal{I}}\{|y_i - z_i|\} \Rightarrow d_\infty(x,z) \leq d_\infty(x,y)+d_\infty(y,z).$
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Minkowski's Inequality}
\begin{equation*}
    (\sum_{k=1}^{n}|\alpha_k+\beta_k|^p)^\frac{1}{p} \leq (\sum_{k=1}^{n}|\alpha_k|^p)^\frac{1}{p} + (\sum_{k=1}^{n}|\beta_k|^p)^\frac{1}{p}
\end{equation*}
$(\sum_{k=1}^{n}|\alpha_k|^p)^\frac{1}{p} = ||\alpha||_p$ is called the
p-norm.The proof makes use of H\"older's inequality. It is first shown that if
$\alpha$ and $\beta$ have a finite p-norm, so does $\alpha+\beta$ (convexity
arguments).
\begin{equation*}
    ||\alpha+\beta||_p^p = \int |\alpha+\beta|^p \,d\mu \leq \int (|\alpha|+|\beta|)|\alpha+\beta|^{p-1} \,d\mu
\end{equation*}
H\"older's inequality on the $L_k$ norm $||rs||_1 \leq ||r||_p||s||_q, \frac{1}{p} + \frac{1}{q} = 1$. \\
Now, applying H\"older's inequality (split product $\frac{1}{p} = p, \frac{1}{q} = 1-\frac{1}{p}$:
\begin{equation*}
||\alpha+\beta||_p^p \leq  (||\alpha||_p+||\beta||_p)\frac{||\alpha+\beta||_p^p}{||\alpha+\beta||_p}
\end{equation*}
Rearranging this gives:
\begin{equation*}
||\alpha+\beta||_p \leq  ||\alpha||_p+||\beta||_p
\end{equation*}
\end{frame}

\begin{frame}
\frametitle{Minkowski's Inequality for the Euclidean Metric}
For the case of the Euclidean metric, the inequality boils down to:
\begin{equation*}
    \sqrt{\sum_{i=1}^{n} |x_i - z_i|^2} \leq  \sqrt{\sum_{i=1}^{n} |x_i - y_i|^2} +  \sqrt{\sum_{i=1}^{n} |y_i - z_i|^2}
\end{equation*}
For $n=1$, we retrieve the well-known inequality
\begin{equation*}
    \sqrt{|x_1 - z_1|^2} \leq  \sqrt{|x_1 - y_1|^2} +  \sqrt{|y_1 - z_1|^2}
\Rightarrow|x_1 - z_1|\leq |x_1 - y_1|+|y_1 - z_1|
\end{equation*} 
\end{frame}